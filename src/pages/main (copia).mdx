---
title: Human Skin Detection in Color Images
description: Skin detection is the process of discriminating skin and non-skin pixels in an arbitrary image and represents an intermediate step in several image processing tasks, such as facial analysis and biomedical segmentation. Different approaches have been presented in the literature, but a comparison is diffcult to perform due to multiple datasets and varying performance measurements. In this work, the datasets and the state-of-the-art approaches are reviewed and categorized using a new proposed taxonomy. Three different representative skin detector methods of the state of the art are selected and thoroughly analyzed. This approaches are then evaluated on three different state of the art datasets and skin tones sub-datasets using multiple metrics. The evaluation is performed on single and cross dataset scenario to highlight key differences between methods, reporting also the inference time. Finally, the results are organized into multiple tables, using the related figures as an assistance tool to support the discussion. Experimental results demonstrate the strength and weaknesses of each approach, and the need to involve multiple metrics for a fair assessment of the method’s aspects.
---
<!-- hide_table_of_contents: true -->


import { ReactCompareSlider, ReactCompareSliderImage } from 'react-compare-slider';
import { ArcherContainer, ArcherElement } from 'react-archer';

export const Center = ({children}) => (
  <div style={{
      display: 'flex',
      alignItems: 'center',
      justifyContent: 'center',
  }}>
    {children}
  </div>
)

export const TwoItems = ({one, two}) => (
  <div class="container margin-bottom--xl">
    <div class="row">
      <div class="col col--6">
        {one}
      </div>
      <div class="col col--6">
        {two}
      </div>
    </div>
  </div>
)

export const Caption = ({children}) => (
  <p class="text--center" style={{color: 'var(--ifm-color-gray-600)'}}>{children}</p>
)


export const rootStyle = { display: 'flex', justifyContent: 'center' };
export const rowStyle = { margin: '200px 0', display: 'flex', justifyContent: 'space-between', }
export const boxStyle = { padding: '10px', border: '1px solid black', };

export const Taxonomy = () => {
  return (
    <div>
 
      <ArcherContainer strokeColor='red' >
        <div style={rootStyle}>
          <ArcherElement
            id="root"
            relations={[{
              targetId: 'element2',
              targetAnchor: 'top',
              sourceAnchor: 'bottom',
            }]}
          >
            <div style={boxStyle}>Root</div>
          </ArcherElement>
        </div>
 
        <div style={rowStyle}>
          <ArcherElement
            id="element2"
            relations={[{
              targetId: 'element3',
              targetAnchor: 'left',
              sourceAnchor: 'right',
              style: { strokeColor: 'blue', strokeWidth: 1 },
              label: <div style={{ marginTop: '-20px' }}>Arrow 2</div>,
            }]}
          >
            <div style={boxStyle}>Element 2</div>
          </ArcherElement>
 
          <ArcherElement id="element3">
            <div style={boxStyle}>Element 3</div>
          </ArcherElement>
 
          <ArcherElement
            id="element4"
            relations={[{
              targetId: 'root',
              targetAnchor: 'right',
              sourceAnchor: 'left',
              label: 'Arrow 3',
            }]}
          >
            <div style={boxStyle}>Element 4</div>
          </ArcherElement>
        </div>
      </ArcherContainer>
 
    </div>
  );
}



<div class="container">

<div class="container margin-bottom--xl">
  <h1 class="text--center">Human Skin Detection in Color Images</h1>
  <div class="msubtitle">
    <p class="hero__subtitle text--center" style={{color: 'var(--ifm-color-gray-600)'}}>Thesis Overview</p>
    <a class="button button--primary" href="#url">See full thesis</a>
  </div>
  <p class="text--center margin-top--lg">
  The purpose of the thesis is to present a review of the <b>human
  skin detection</b> datasets and approaches of the state of the
  art, and then perform a comparative in-depth analysis of the
  most relevant methods on different databases.
  </p>
</div>


<!--dic class="text--center"
<div class="text--center">
  <p style={{color: 'var(--ifm-color-gray-600)'}}>
  The purpose of the thesis is to present a review of the <b>human
  skin detection</b> datasets and approaches of the state of the
  art, and then perform a comparative in-depth analysis of the
  most relevant methods on different databases.
  </p>
</div>
-->

<!-- TODO: change page title!!>

<!--div class="margin-vert--lg" style={{margin: '0 0 var(--ifm-paragraph-margin-bottom)'}}-->
<div class="margin-vert--lg">
  <Center>
    <ReactCompareSlider
      itemOne={<ReactCompareSliderImage src="/img/skin_det_ori3.jpg" alt="Original image" />}
      itemTwo={<ReactCompareSliderImage src="/img/skin_det_red3.png" alt="Detected skin pixels" />}
      style={{
      display: "flex",
      width: "450px",
      maxWidth: "90vw",
      height: "auto"
      }}
    />
  </Center>
</div>


<p>
Skin detection is the process of <b>discriminating skin and non-skin pixels</b>. It is
quite a challenging process because of the large color diversity that objects and
human skin can assume, and scene properties such as lighting and background.
</p>


<!-- TODO: refactor code (follow a react quick tutorial)
<TwoItems
  one={<p>asdasd</p>}
  two={<p>asdasd</p>} >
</TwoItems>
-->


<!-- TODO: INSTEAD of tooltip / details, just display some images in background!! OR carousel at the bottom-->
<div class="container margin-bottom--xl">
  <div class="row">
    <div class="col col--6 margin-top--md">
      <h3>Applications</h3>
      <ul>
        <li><b>Facial Analysis</b></li>
        <li>Gesture Analysis</li>
        <li><b>Biomedical</b></li>
        <li>Video Surveillance</li>
        <li>Content Filter</li>
        <li>Advertisement</li>
      </ul>
    </div>
    <div class="col col--6">
    </div>
  </div>
  <div class="row margin-top--md">
    <div class="col col--6">
      <h3>Limitations</h3>
      <ul>
        <li>Materials with <b>skin-like colors</b></li>
        <li>Wide range of <b>skin tones</b></li>
        <li><b>Illumination</b></li>
        <li>Cameras color science</li>
      </ul>
    </div>
    <div class="col col--6">
    </div>
  </div>
</div>





## Methodological Approach

<div class="container margin-top--lg margin-bottom--lg">
  <div class="invert">
    <img class="svg" src="/img/methodological-approach.svg" alt="Methodological approach flowchart" style={{margin: "0 0 var(--ifm-paragraph-margin-bottom)"}} />
  </div>
</div>


## Taxonomy


<p>
Skin detection is a <b>binary classification problem</b>: the pixels of an image must be divided between skin and non-skin classes.
</p>
<p>
One of several ways to categorize methods is to group them according to how the pixel classification is done.
</p>

<div class="container invert margin-bottom--xl" style={{position: "relative"}}>
  <img src="/img/taxonomy.png" />
  <a class="button button--outline button--primary" style={{position:"absolute", right:"0px", top:"0px"}} href="#dynamic-thresholding">Some link</a>
</div>

<img src="/img/taxonomy.svg" />

<div>
  <div class="taxonomy-row margin-vert--lg">
    <div class="taxonomy-col" />
    <div class="taxonomy-col">
      <p class="text--center">Rule-based <br />classifier</p>
    </div>
    <div class="taxonomy-col taxonomy-group">
      <a class="taxonomy-link" href="#taxonomy-1">Thresholding</a>
      <a class="taxonomy-link" href="#taxonomy-1">Fuzzy Logic</a>
    </div>
  </div>
  <div class="taxonomy-row margin-vert--lg">
    <div class="taxonomy-col">
      <p class="text--center">Skin Detector</p>
    </div>
    <div class="taxonomy-col">
      <p class="text--center">Machine Learning <br />classifier</p>
    </div>
    <div class="taxonomy-col taxonomy-group">
      <a class="taxonomy-link" href="#taxonomy-1">Deep Learning</a>
      <a class="taxonomy-link" href="#taxonomy-1">Statistical</a>
      <a class="taxonomy-link" href="#taxonomy-1">Ensemble</a>
    </div>
  </div>
  <div class="taxonomy-row margin-vert--lg">
    <div class="taxonomy-col" />
    <div class="taxonomy-col" style={{display: "flex", flexDirection: "column"}}>
      <a class="taxonomy-link" href="#taxonomy-1">Hybrid classifier</a>
    </div>
    <div class="taxonomy-col" />
  </div>
</div>


<Taxonomy />


<!-- h3 class="margin-bottom--lg">Dynamic Thresholding</h3 -->
<!-- TODO: refactor as React component -->
<div class="container margin-bottom--xl">

  ## Dynamic Thresholding

  <div class="row margin-top--lg">
    <div class="col col--6">
      <Center>
        <div>
          <h3 class="no-bold margin-left--md">Algorithm Overview</h3>
          <ol class="spacing">
            <li>Input image RGB to YCbCr</li>
            <li>Cr<sub>max</sub> Cb<sub>min</sub> computation</li>
            <li>Pixel-wise computation of the correlation rules parameters</li>
            <li>Pixel-wise correlation rules check</li>
          </ol>
        </div>
      </Center>
    </div>
    <div class="col col--6">
      <Center>
        <div class="invert">
          <img src="/img/trapezia_params.png" style={{width: "100%", maxWidth: "450px"}} />
          <Caption>Brancati et al. 2017 [3]</Caption>
        </div>
      </Center>
    </div>
  </div>
  <p>
  The skin pixels clusters assume a trapezoidal shape in the YCb and YCr color subspaces. Moreover, the shape and size of the trapezium vary according to many factors, such as the illumination conditions. In high illumination conditions, the base of the trapezium results larger.
  </p>
  <p>
  Besides, the chrominance components of a skin pixel P with coordinates (P<sub>Y</sub>, P<sub>Cb</sub>, P<sub>Cr</sub>) in the YCbCr space exhibit the following behavior: the further is the (P<sub>Y</sub>, P<sub>Cr</sub>) point from the longer base of the trapezium in the YCr subspace, the further is the (P<sub>Y</sub>, P<sub>Cb</sub>) point from the longer base of the trapezium in the YCb subspace, and vice versa.
  </p>
  <p>
  The aforementioned observations are the base of the method: it tries to define image-specific trapeziums in the YCb and YCr color subspaces and then verifies that the correlation rules between the two subspaces reflect the inversely proportional behavior of the chrominance components.
  </p>
</div>


<div class="container margin-bottom--xl">

  ## Statistical

  <div class="row">
    <div class="col col-12">
      <div>
        <div class="im-container50 margin-vert--md">
          <img src="/img/3d-hist-orig.jpg" />
          <img src="/img/3d-hist-plug.png" />
        </div>
        <Center>
          <Caption>Example of a 3D Histogram</Caption>
        </Center>
      </div>
    </div>
  </div>
  <div class="row margin-top--md">
    <div class="col col--6">
      <Center>
        <div>
          <h3 class="no-bold margin-left--md">Train</h3>
          <ol class="spacing margin-bottom--lg">
            <li>Initialize the skin and non-skin 3D histograms</li>
            <li>Pick (image, mask) from the training set</li>
            <li>Loop every RGB pixel from image</li>
            <li>By checking its mask, the pixel its either skin or non-skin. Add +1 to the relative histogram count at coordinates [r,g,b]</li>
            <li>Return to step 2 until there are images</li>
          </ol>
        </div>
      </Center>
    </div>
    <div class="col col--6">
      <Center>
        <div>
          <h3 class="no-bold margin-left--md">Predict</h3>
          <ol class="spacing margin-bottom--lg">
            <li>Define classifying threshold Θ</li>
            <li>Loop every RGB pixel from input image</li>
            <li>Calculate RGB probability of being skin</li>
            <li>If skin probability > Θ, it is classified as skin</li>
          </ol>
        </div>
      </Center>
    </div>
  </div>
  <p>
  The data is modeled with two 3D histograms representing the probabilities of skin and non-skin classes, and classification is performed via probability calculus by measuring the probability <i>P</i> of each <i>rgb</i> pixel to belong to the <i>skin</i> class:
  </p>
  <Center>
    <div class="invert">
      <img class="svg" src="/img/probability.svg" alt="Probability function" style={{margin: "0 0 var(--ifm-paragraph-margin-bottom)"}} />
    </div>
  </Center>
  <p>
  where <i>s[rgb]</i> is the pixel count contained in bin <i>rgb</i> of the skin histogram and <i>n[rgb]</i> is the equivalent count from the non-skin histogram. <br />
  A particular <i>rgb</i> value is labeled skin if:
  </p>
  <Center>
    <div class="invert">
      <img class="svg" src="/img/probability_thresh.svg" alt="Probability function" style={{margin: "0 0 var(--ifm-paragraph-margin-bottom)"}} />
    </div>
  </Center>
  <p>
  where 0 ≤ Θ ≤ 1 is a threshold value that can be adjusted to trade-off between true positives and false positives.
  </p>
</div>


<!--TODO: srcset with only 3 layers on cell for SVG dense -->
<div class="container margin-bottom--xl">

  ## U-Net

  <div class="row margin-top--lg">
    <div class="col col--6">
      <Center>
        <div>
          <h3 class="no-bold margin-left--md">Workflow</h3>
          <ol class="spacing">
            <li>Pre-process input image: resize (512×512)px, padding</li>
            <li>Extract features in the <b>contracting pathway</b> via convolutions and down-sampling: the spatial information is lost while advanced features are learnt</li>
            <li>Try to retrieve spatial information through up-sampling in the <b>expansive pathway</b> and direct concatenations of dense blocks coming from the contracting pathway</li>
            <li>Provide a final classification map</li>
          </ol>
        </div>
      </Center>
    </div>
    <div class="col col--6">
      <Center>
        <div>
          <img src="/img/skinny_arch.png" style={{width: "100%", maxWidth: "450px"}} />
          <Caption>Tarasiewicz et al. 2020 [5]</Caption>
        </div>
      </Center>
    </div>
  </div>
  <p>
  The Skinny network consists of a modified U-Net incorporating dense blocks and inception modules to benefit from a wider spatial context.
  </p>
  <p>
  An additional deep level is appended to the original U-Net model, to better capture large-scale contextual features in the deepest part of the network.
  The features extracted in the contracting path propagate to the corresponding expansive levels through the dense blocks.
  </p>
  <p>
  The original U-Net convolutional layers are replaced with the inception modules: before each max-pooling layer, in the contracting path, and after concatenating features, in the expanding path.
  Thanks to these architectural choices, Skinny benefits from a wider pixel context.
  </p>
  <div class="container margin-top--lg">
    <div class="im-container padding-small" >
      <img src="/img/inception1.png" class="three-cols" />
      <img src="/img/inception2.png" class="three-cols" />
      <img src="/img/inception3.png" class="three-cols" />
    </div>
    <p>
    The salient content size varies between images. <b>Inception module</b> combines multiple kernels with different sizes for content adaptation.
    </p>
    <Center>
      <div class="invert">
        <img src="/img/dense.svg" style={{padding: "0 0 0.4rem 0"}} />
      </div>
    </Center>
    <p>
    <b>Dense block</b> layers are connected in a way that each one receives feature maps from all preceding layers and passes its feature maps to all subsequent layers.
    </p>
  </div>
</div>


<!-- Bibliography?? TODO-->
<!--
<ol>
   <li id="#nbrancati">N. Brancati, G. De Pietro,M. Frucci, and L. Gallo. “Human skin detection through correlation rules between the YCb and YCr subspaces based on dynamic color clustering”. Computer Vision and Image Understanding 155, 2017, pp. 33–42. <a href="https://doi.org/10.1016/j.cviu.2016.12.001">https://doi.org/10.1016/j.cviu.2016.12.001</a></li>
</ol>

<q cite='#nbrancati'>who would not groan at hearing that Roman knights and senators grovel 
before her (Cleopatra) like eunuchs?</q>
<script>
   var quotes = document.getElementsByTagName('q');
   for (var i in quotes) {
      quotes[i].addEventListener('click', function() { 
         window.location = this.getAttribute('cite'); },
      false);
   }
</script>
-->

</div>
